# llm-connector å‡çº§åˆ° 0.3.8

## å‡çº§æ¦‚è¿°

å·²å°† `llm-connector` ä»ç‰ˆæœ¬ 0.3.1 å‡çº§åˆ°æœ€æ–°çš„ 0.3.8 ç‰ˆæœ¬ï¼Œå¹¶å¯ç”¨äº†æµå¼æ”¯æŒåŠŸèƒ½ã€‚

### ç‰ˆæœ¬ä¿¡æ¯

- **ä¹‹å‰ç‰ˆæœ¬**: 0.3.1
- **å½“å‰ç‰ˆæœ¬**: 0.3.8
- **GitHub ä»“åº“**: https://github.com/lipish/llm-connector
- **å¯ç”¨åŠŸèƒ½**: `streaming`

## ä¸»è¦å˜æ›´

### 1. Cargo.toml æ›´æ–°

```toml
# ä¹‹å‰
llm-connector = "0.3.1"

# ç°åœ¨
llm-connector = { version = "0.3.8", features = ["streaming"] }
```

### 2. ä¸“ç”¨æ„é€ å‡½æ•°æ”¯æŒ

llm-connector 0.3.8 ä¸ºä¸»è¦åè®®æä¾›äº†ä¸“ç”¨çš„æ„é€ å‡½æ•°ï¼š

```rust
// Zhipu AI - ä½¿ç”¨ä¸“ç”¨æ„é€ å‡½æ•°
LlmClient::zhipu(api_key)

// Aliyun DashScope - ä½¿ç”¨ä¸“ç”¨æ„é€ å‡½æ•°  
LlmClient::aliyun(api_key)

// Anthropic - å·²æœ‰ä¸“ç”¨æ„é€ å‡½æ•°
LlmClient::anthropic(api_key)

// OpenAI åŠå…¼å®¹æä¾›å•† - é€šç”¨æ„é€ å‡½æ•°
LlmClient::openai(api_key, endpoint)

// Ollama - æœ¬åœ°æœåŠ¡ï¼Œæ— éœ€ API key
LlmClient::ollama(endpoint)
```

### 3. æ–°å¢åŠŸèƒ½

#### 3.1 æ¨¡å‹å‘ç°ï¼ˆModel Discoveryï¼‰

å¯ä»¥åŠ¨æ€è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼š

```rust
let model = LlmModel::from_config(config)?;

// è·å–å¯ç”¨æ¨¡å‹
let models = model.fetch_available_models().await?;
```

**æ”¯æŒæƒ…å†µ**:
- âœ… OpenAI Protocol (åŒ…æ‹¬ DeepSeek, Moonshot ç­‰å…¼å®¹æä¾›å•†)
- âœ… Anthropic Protocol (æœ‰é™æ”¯æŒ)
- âœ… Ollama Protocol (å®Œæ•´æ”¯æŒï¼Œé€šè¿‡ /api/tags)
- âœ… Zhipu Protocol (é€šè¿‡ä¸“ç”¨ç«¯ç‚¹)
- âŒ Aliyun Protocol (ä¸æ”¯æŒ)

#### 3.2 åè®®ä¿¡æ¯æŸ¥è¯¢

```rust
let protocol = model.protocol_name();
println!("å½“å‰ä½¿ç”¨çš„åè®®: {}", protocol);
```

#### 3.3 Ollama æ¨¡å‹ç®¡ç†

llm-connector 0.3.8 æä¾›äº†å®Œæ•´çš„ Ollama æ¨¡å‹ç®¡ç†åŠŸèƒ½ï¼š

```rust
use llm_connector::ollama::OllamaModelOps;

let client = LlmClient::ollama(None);

// åˆ—å‡ºæ‰€æœ‰å·²å®‰è£…çš„æ¨¡å‹
let models = client.list_models().await?;

// æ‹‰å–æ–°æ¨¡å‹
client.pull_model("llama3.2").await?;

// æŸ¥çœ‹æ¨¡å‹è¯¦æƒ…
let details = client.show_model("llama3.2").await?;

// åˆ é™¤æ¨¡å‹
client.delete_model("llama3.2").await?;
```

#### 3.4 å¢å¼ºçš„æµå¼æ”¯æŒ

ç°åœ¨æ”¯æŒæ›´å¥½çš„ Anthropic æµå¼å“åº”å¤„ç†ï¼š

```rust
use futures_util::StreamExt;

let mut stream = client.chat_stream(&request).await?;

while let Some(chunk) = stream.next().await {
    let chunk = chunk?;
    if let Some(content) = chunk.get_content() {
        print!("{}", content);
    }
}
```

## ä»£ç æ›´æ–°

### src/models.rs

æ›´æ–°äº† `create_client()` æ–¹æ³•ä»¥ä½¿ç”¨æ–°çš„ä¸“ç”¨æ„é€ å‡½æ•°ï¼š

```rust
match &config.provider {
    ModelProvider::Anthropic => {
        Ok(LlmClient::anthropic(api_key))
    }
    ModelProvider::Zhipu => {
        // ä½¿ç”¨ä¸“ç”¨æ„é€ å‡½æ•°ï¼ˆ0.3.8+ï¼‰
        Ok(LlmClient::zhipu(api_key))
    }
    ModelProvider::Aliyun => {
        // ä½¿ç”¨ä¸“ç”¨æ„é€ å‡½æ•°ï¼ˆ0.3.8+ï¼‰
        Ok(LlmClient::aliyun(api_key))
    }
    ModelProvider::OpenAI => {
        // OpenAI åŠå…¼å®¹æä¾›å•†ä½¿ç”¨é€šç”¨æ„é€ å‡½æ•°
        let endpoint = config.endpoint.as_deref();
        Ok(LlmClient::openai(api_key, endpoint))
    }
    ModelProvider::Ollama => {
        let endpoint = config.endpoint.as_deref();
        Ok(LlmClient::ollama(endpoint))
    }
    // ... å…¶ä»–æä¾›å•†ä½¿ç”¨ openai() å…¼å®¹æ¨¡å¼
}
```

æ–°å¢æ–¹æ³•ï¼š

```rust
impl LlmModel {
    /// è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
    pub async fn fetch_available_models(&self) -> Result<Vec<String>, ModelError> {
        self.client.fetch_models().await
            .map_err(|e| ModelError::APIError(format!("Failed to fetch models: {}", e)))
    }
    
    /// è·å–åè®®åç§°
    pub fn protocol_name(&self) -> String {
        self.client.protocol_name().to_string()
    }
}
```

## æ”¯æŒçš„åè®®

### 1. OpenAI Protocol
- æ ‡å‡† OpenAI API
- å…¼å®¹æä¾›å•†: DeepSeek, Moonshot, LongCat, VolcEngine ç­‰
- ç‰¹æ€§: âœ… æ¨¡å‹å‘ç°, âœ… æµå¼, âœ… å·¥å…·è°ƒç”¨

### 2. Anthropic Protocol
- Claude Messages API
- æ¨¡å‹: claude-3-5-sonnet, claude-3-opus, claude-3-haiku
- ç‰¹æ€§: âœ… æœ‰é™æ¨¡å‹å‘ç°, âœ… å¢å¼ºæµå¼æ”¯æŒ, âœ… å·¥å…·è°ƒç”¨

### 3. Zhipu Protocol (æ™ºè°±AI)
- ä½¿ç”¨ä¸“ç”¨æ„é€ å‡½æ•° `LlmClient::zhipu()`
- æ¨¡å‹: glm-4, glm-4-flash, glm-4-air, glm-4-plus
- ç‰¹æ€§: âœ… æ¨¡å‹å‘ç°, âœ… OpenAI å…¼å®¹æ ¼å¼

### 4. Aliyun Protocol (é˜¿é‡Œäº‘ DashScope)
- ä½¿ç”¨ä¸“ç”¨æ„é€ å‡½æ•° `LlmClient::aliyun()`
- æ¨¡å‹: qwen-turbo, qwen-plus, qwen-max
- ç‰¹æ€§: âŒ ä¸æ”¯æŒæ¨¡å‹å‘ç°

### 5. Ollama Protocol (æœ¬åœ°)
- æ— éœ€ API key
- å®Œæ•´çš„æ¨¡å‹ç®¡ç†åŠŸèƒ½
- ç‰¹æ€§: âœ… å®Œæ•´æ¨¡å‹å‘ç°, âœ… CRUD æ“ä½œ, âœ… æµå¼

## æµ‹è¯•éªŒè¯

### è¿è¡ŒåŠŸèƒ½æ¼”ç¤º

```bash
cargo run --example llm_connector_features
```

### æ¼”ç¤ºè¾“å‡º

```
ğŸš€ llm-connector 0.3.8 åŠŸèƒ½æ¼”ç¤º
================================================================================

ğŸ“– Demo 1: OpenAI Protocol
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âš ï¸  æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡ï¼Œè·³è¿‡æ­¤æ¼”ç¤º

ğŸ“– Demo 2: Zhipu Protocol (æ™ºè°±AI)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âš ï¸  æœªè®¾ç½® ZHIPU_API_KEY ç¯å¢ƒå˜é‡ï¼Œè·³è¿‡æ­¤æ¼”ç¤º
   æç¤º: Zhipu AI ç°åœ¨æœ‰ä¸“ç”¨çš„æ„é€ å‡½æ•° LlmClient::zhipu()

ğŸ“– Demo 3: Aliyun Protocol (é˜¿é‡Œäº‘ DashScope)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âš ï¸  æœªè®¾ç½® ALIYUN_API_KEY ç¯å¢ƒå˜é‡ï¼Œè·³è¿‡æ­¤æ¼”ç¤º
   æç¤º: Aliyun DashScope ç°åœ¨æœ‰ä¸“ç”¨çš„æ„é€ å‡½æ•° LlmClient::aliyun()

ğŸ“– Demo 4: Ollama Protocol (æœ¬åœ°æ¨¡å‹)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ åè®®: ollama
âœ“ æ¨¡å‹åç§°: llama3.2
âœ“ æ— éœ€ API key
âœ“ æœ¬åœ°å·²å®‰è£…çš„æ¨¡å‹:
  1. glm-4
  2. glm-4.6
  3. glm-4-plus
  4. glm-4-flash
  5. glm-4-air
  6. glm-4-long
```

## å…¼å®¹æ€§

### å‘åå…¼å®¹

å‡çº§åˆ° 0.3.8 ä¿æŒäº†å‘åå…¼å®¹æ€§ï¼š

- âœ… ç°æœ‰çš„ OpenAI å…¼å®¹æä¾›å•†ä»ç„¶å·¥ä½œ
- âœ… Anthropic æ„é€ å‡½æ•°ä¿æŒä¸å˜
- âœ… Ollama æ„é€ å‡½æ•°ä¿æŒä¸å˜
- âœ… åªæ˜¯ Zhipu å’Œ Aliyun è·å¾—äº†æ›´ä¼˜åŒ–çš„ä¸“ç”¨æ„é€ å‡½æ•°

### API å˜æ›´

| æä¾›å•† | 0.3.1 | 0.3.8 | è¯´æ˜ |
|--------|-------|-------|------|
| OpenAI | `openai(key, endpoint)` | `openai(key, endpoint)` | æ— å˜åŒ– |
| Anthropic | `anthropic(key)` | `anthropic(key)` | æ— å˜åŒ– |
| Zhipu | `openai(key, endpoint)` | `zhipu(key)` â­ | æ–°å¢ä¸“ç”¨æ„é€ å‡½æ•° |
| Aliyun | `openai(key, endpoint)` | `aliyun(key)` â­ | æ–°å¢ä¸“ç”¨æ„é€ å‡½æ•° |
| Ollama | `ollama(endpoint)` | `ollama(endpoint)` | æ— å˜åŒ– |

## é…ç½®ç¤ºä¾‹

### OpenAI

```rust
ModelConfig {
    provider: ModelProvider::OpenAI,
    model_name: "gpt-4".to_string(),
    api_key: Some(api_key),
    endpoint: None, // ä½¿ç”¨é»˜è®¤ç«¯ç‚¹
    max_tokens: 4096,
    temperature: 0.7,
}
```

### Zhipu (ä½¿ç”¨æ–°çš„ä¸“ç”¨æ„é€ å‡½æ•°)

```rust
ModelConfig {
    provider: ModelProvider::Zhipu,
    model_name: "glm-4".to_string(),
    api_key: Some(api_key),
    endpoint: None, // llm-connector è‡ªåŠ¨ä½¿ç”¨æ­£ç¡®çš„ç«¯ç‚¹
    max_tokens: 4096,
    temperature: 0.7,
}
```

### Aliyun (ä½¿ç”¨æ–°çš„ä¸“ç”¨æ„é€ å‡½æ•°)

```rust
ModelConfig {
    provider: ModelProvider::Aliyun,
    model_name: "qwen-max".to_string(),
    api_key: Some(api_key),
    endpoint: None, // llm-connector è‡ªåŠ¨ä½¿ç”¨æ­£ç¡®çš„ç«¯ç‚¹
    max_tokens: 4096,
    temperature: 0.7,
}
```

### Ollama (æœ¬åœ°)

```rust
ModelConfig {
    provider: ModelProvider::Ollama,
    model_name: "llama3.2".to_string(),
    api_key: None, // æ— éœ€ API key
    endpoint: None, // é»˜è®¤ localhost:11434
    max_tokens: 4096,
    temperature: 0.7,
}
```

## ç¯å¢ƒå˜é‡æ”¯æŒ

llm-connector æ”¯æŒä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š

```bash
export OPENAI_API_KEY="sk-..."
export ANTHROPIC_API_KEY="sk-ant-..."
export ZHIPU_API_KEY="sk-..."
export ALIYUN_API_KEY="sk-..."
export DEEPSEEK_API_KEY="sk-..."
export MOONSHOT_API_KEY="sk-..."
export LONGCAT_API_KEY="ak-..."
```

## ä¸‹ä¸€æ­¥è®¡åˆ’

### Phase 1: æµå¼æ”¯æŒé›†æˆ âœ…

- [x] å‡çº§åˆ° 0.3.8
- [x] å¯ç”¨ streaming ç‰¹æ€§
- [ ] åœ¨ LanguageModel trait ä¸­æ·»åŠ æµå¼æ–¹æ³•
- [ ] å®ç°æµå¼å“åº”å¤„ç†

### Phase 2: å·¥å…·è°ƒç”¨å¢å¼º

- [ ] åˆ©ç”¨ llm-connector çš„å·¥å…·è°ƒç”¨æ”¯æŒ
- [ ] å®ç° `complete_with_tools()` çš„å®é™…é€»è¾‘
- [ ] æ·»åŠ å·¥å…·è°ƒç”¨ç¤ºä¾‹

### Phase 3: æ¨¡å‹å‘ç°é›†æˆ

- [ ] åœ¨å¯åŠ¨æ—¶è‡ªåŠ¨è·å–å¯ç”¨æ¨¡å‹
- [ ] ç¼“å­˜æ¨¡å‹åˆ—è¡¨ä»¥å‡å°‘ API è°ƒç”¨
- [ ] æä¾›æ¨¡å‹é€‰æ‹©å»ºè®®

### Phase 4: Ollama ç®¡ç†ç•Œé¢

- [ ] åˆ›å»º Ollama æ¨¡å‹ç®¡ç† CLI
- [ ] æ”¯æŒæ¨¡å‹æ‹‰å–ã€åˆ é™¤ã€æŸ¥çœ‹è¯¦æƒ…
- [ ] é›†æˆåˆ°ä¸»ç¨‹åºä¸­

## å‡çº§æ£€æŸ¥æ¸…å•

- [x] æ›´æ–° Cargo.toml ä¸­çš„ç‰ˆæœ¬å·
- [x] å¯ç”¨ streaming ç‰¹æ€§
- [x] æ›´æ–° Zhipu ä½¿ç”¨ä¸“ç”¨æ„é€ å‡½æ•°
- [x] æ›´æ–° Aliyun ä½¿ç”¨ä¸“ç”¨æ„é€ å‡½æ•°
- [x] æ·»åŠ  `fetch_available_models()` æ–¹æ³•
- [x] æ·»åŠ  `protocol_name()` æ–¹æ³•
- [x] åˆ›å»ºåŠŸèƒ½æ¼”ç¤ºç¤ºä¾‹
- [x] éªŒè¯æ„å»ºæˆåŠŸ
- [x] éªŒè¯ Ollama é›†æˆæ­£å¸¸å·¥ä½œ
- [ ] æ›´æ–°æ–‡æ¡£
- [ ] æ·»åŠ æµå¼æ”¯æŒç¤ºä¾‹

## å‚è€ƒèµ„æº

- **GitHub**: https://github.com/lipish/llm-connector
- **æ–‡æ¡£**: README ä¸­åŒ…å«äº†å®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹
- **ç¤ºä¾‹ä»£ç **: `examples/llm_connector_features.rs`

## æ€»ç»“

llm-connector 0.3.8 å‡çº§æˆåŠŸå®Œæˆï¼Œå¸¦æ¥äº†ä»¥ä¸‹æ”¹è¿›ï¼š

1. **æ›´ä¼˜åŒ–çš„ API**: Zhipu å’Œ Aliyun è·å¾—äº†ä¸“ç”¨æ„é€ å‡½æ•°
2. **æ¨¡å‹å‘ç°**: å¯ä»¥åŠ¨æ€è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
3. **Ollama å¢å¼º**: å®Œæ•´çš„æ¨¡å‹ç®¡ç†åŠŸèƒ½
4. **æµå¼æ”¹è¿›**: æ›´å¥½çš„ Anthropic æµå¼æ”¯æŒ
5. **å‘åå…¼å®¹**: ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹å³å¯å·¥ä½œ

æ‰€æœ‰ç°æœ‰åŠŸèƒ½ä¿æŒæ­£å¸¸å·¥ä½œï¼Œæ–°åŠŸèƒ½å·²å‡†å¤‡å¥½é›†æˆåˆ°åç»­å¼€å‘ä¸­ã€‚
