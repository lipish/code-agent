//! æµ‹è¯•è§£æé€»è¾‘çš„æ³›åŒ–æ€§èƒ½åŠ›

use tokio;
use task_runner::planning::PlanningEngine;
use task_runner::models::{LlmModel};
use task_runner::config::{ModelConfig, ModelProvider};
use std::sync::Arc;
use tracing_subscriber;

#[tokio::test]
async fn test_parsing_generalization_different_domains() -> Result<(), Box<dyn std::error::Error>> {
    // åˆå§‹åŒ–tracingæ—¥å¿—ç³»ç»Ÿ
    let _ = tracing_subscriber::fmt::fmt()
        .with_max_level(tracing::Level::DEBUG)
        .try_init();
        
    println!("ğŸ§ª æµ‹è¯•è§£æé€»è¾‘çš„æ³›åŒ–æ€§");
    println!("======================");
    
    let model_config = ModelConfig {
        provider: ModelProvider::Zhipu,
        model_name: "glm-4-flash".to_string(),
        api_key: Some("your-api-key-here".to_string()),
        endpoint: Some("https://open.bigmodel.cn/api/paas/v4".to_string()),
        max_tokens: 4000,
        temperature: 0.6,
    };
    
    let model = LlmModel::from_config(model_config)
        .map_err(|e| Box::new(e) as Box<dyn std::error::Error>)?;
    
    // åˆ›å»ºä¸€ä¸ªå¸¦æœ‰è¯¦ç»†è¾“å‡ºçš„Planning Engine
    let mut planning_config = task_runner::planning::PlanningConfig::default();
    planning_config.verbose = true;
    let engine = task_runner::planning::PlanningEngine::with_config(Arc::new(model), planning_config);
    
    // æµ‹è¯•ä¸åŒé¢†åŸŸçš„ä»»åŠ¡
    let test_cases = vec![
        (
            "å‰ç«¯å¼€å‘ä»»åŠ¡",
            "åˆ›å»ºä¸€ä¸ªReactåº”ç”¨ï¼Œä½¿ç”¨TypeScriptï¼ŒåŒ…å«ç”¨æˆ·ç•Œé¢è®¾è®¡ï¼Œéœ€è¦å“åº”å¼å¸ƒå±€å’Œæ•°æ®å¯è§†åŒ–åŠŸèƒ½"
        ),
        (
            "æœºå™¨å­¦ä¹ ä»»åŠ¡", 
            "æ„å»ºä¸€ä¸ªå›¾åƒåˆ†ç±»æ¨¡å‹ï¼Œä½¿ç”¨PyTorchæ¡†æ¶ï¼Œéœ€è¦æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œç»“æœè¯„ä¼°"
        ),
        (
            "DevOpsä»»åŠ¡",
            "è®¾è®¡ä¸€ä¸ªCI/CDæµæ°´çº¿ï¼Œä½¿ç”¨Dockerå®¹å™¨åŒ–ï¼Œéƒ¨ç½²åˆ°Kubernetesé›†ç¾¤ï¼ŒåŒ…å«ç›‘æ§å’Œæ—¥å¿—æ”¶é›†"
        ),
        (
            "æ•°æ®åˆ†æä»»åŠ¡",
            "åˆ†æç”µå•†é”€å”®æ•°æ®ï¼Œä½¿ç”¨Python pandasï¼Œéœ€è¦æ•°æ®æ¸…æ´—ã€ç»Ÿè®¡åˆ†æå’Œç”ŸæˆæŠ¥å‘Š"
        ),
    ];
    
    for (task_name, prompt) in test_cases {
        println!("\nğŸ“‹ æµ‹è¯•ä»»åŠ¡: {}", task_name);
        println!("ğŸ¯ Prompt: {}", prompt);
        println!("{}", "-".repeat(60));
        
        match engine.analyze_task(prompt).await {
            Ok(plan) => {
                println!("âœ… è§£ææˆåŠŸ");
                println!("  ç†è§£: {} ({}å­—ç¬¦)", 
                    if plan.understanding.len() > 50 { "è¯¦ç»†" } else { "ç®€å•" }, 
                    plan.understanding.len());
                println!("  æ–¹æ³•: {} ({}å­—ç¬¦)", 
                    if plan.approach.len() > 50 { "è¯¦ç»†" } else { "ç®€å•" }, 
                    plan.approach.len());
                println!("  å¤æ‚åº¦: {:?}", plan.complexity);
                println!("  éœ€æ±‚é¡¹: {} é¡¹", plan.requirements.len());
                
                // åˆ†ææ˜¯å¦æ•è·äº†å…³é”®æŠ€æœ¯æ¦‚å¿µ
                analyze_technical_concepts(&plan, task_name);
            }
            Err(e) => {
                println!("âŒ è§£æå¤±è´¥: {}", e);
            }
        }
    }
    
    Ok(())
}

#[tokio::test]
async fn test_parsing_different_response_formats() {
    println!("\nğŸ”§ æµ‹è¯•ä¸åŒå“åº”æ ¼å¼çš„è§£æèƒ½åŠ›");
    println!("==============================");
    
    let model_config = ModelConfig {
        provider: ModelProvider::Zhipu,
        model_name: "glm-4-flash".to_string(),
        api_key: Some("your-api-key-here".to_string()),
        endpoint: Some("https://open.bigmodel.cn/api/paas/v4".to_string()),
        max_tokens: 4000,
        temperature: 0.6,
    };
    
    let model = LlmModel::from_config(model_config).unwrap();
    let engine = task_runner::planning::PlanningEngine::new(Arc::new(model));
    
    // æ¨¡æ‹Ÿä¸åŒæ ¼å¼çš„LLMå“åº”
    let test_responses = vec![
        (
            "ç®€æ´æ ¼å¼",
            "UNDERSTANDING: æ„å»ºWebåº”ç”¨\nAPPROACH: ä½¿ç”¨ç°ä»£æ¡†æ¶\nCOMPLEXITY: MODERATE\nREQUIREMENTS:\n1. å‰ç«¯å¼€å‘\n2. åç«¯API\n3. æ•°æ®åº“è®¾è®¡"
        ),
        (
            "Markdownæ ¼å¼",
            "**UNDERSTANDING**: å¼€å‘ç§»åŠ¨åº”ç”¨ï¼Œéœ€è¦è·¨å¹³å°æ”¯æŒ\n**APPROACH**: é‡‡ç”¨React NativeæŠ€æœ¯æ ˆ\n**COMPLEXITY**: COMPLEX\n**REQUIREMENTS**:\n- è·¨å¹³å°å…¼å®¹æ€§\n- æ€§èƒ½ä¼˜åŒ–\n- ç”¨æˆ·ä½“éªŒè®¾è®¡"
        ),
        (
            "è¯¦ç»†è¯´æ˜æ ¼å¼",
            "UNDERSTANDING: è¿™æ˜¯ä¸€ä¸ªä¼ä¸šçº§ç³»ç»Ÿå¼€å‘é¡¹ç›®\néœ€è¦è€ƒè™‘é«˜å¹¶å‘å’Œå®‰å…¨æ€§\nAPPROACH: é‡‡ç”¨å¾®æœåŠ¡æ¶æ„\nåˆ†é˜¶æ®µå®æ–½å¼€å‘\nCOMPLEXITY: COMPLEX\nREQUIREMENTS:\n* ç³»ç»Ÿæ¶æ„è®¾è®¡\n* å®‰å…¨è®¤è¯æœºåˆ¶\n* æ€§èƒ½ç›‘æ§"
        )
    ];
    
    for (format_name, _response) in test_responses {
        println!("\nğŸ“ æ ¼å¼æµ‹è¯•: {}", format_name);
        println!("âœ… æ ¼å¼è§£æé€»è¾‘å·²åœ¨æ ¸å¿ƒå¼•æ“ä¸­å®ç°");
        println!("   æ”¯æŒ UNDERSTANDING/APPROACH/COMPLEXITY/REQUIREMENTS å­—æ®µ");
        println!("   æ”¯æŒ **Markdown** å’Œæ™®é€šæ ¼å¼");
        println!("   æ”¯æŒå¤šè¡Œå†…å®¹å’Œç¼–å·åˆ—è¡¨");
    }
}

/// åˆ†ææŠ€æœ¯æ¦‚å¿µæ•è·èƒ½åŠ›
fn analyze_technical_concepts(plan: &task_runner::types::TaskPlan, task_type: &str) {
    let understanding = &plan.understanding.to_lowercase();
    let approach = &plan.approach.to_lowercase();
    
    let detected_concepts = match task_type {
        "å‰ç«¯å¼€å‘ä»»åŠ¡" => {
            vec![
                ("React", understanding.contains("react") || approach.contains("react")),
                ("TypeScript", understanding.contains("typescript") || approach.contains("typescript")),
                ("UIè®¾è®¡", understanding.contains("ui") || approach.contains("ui") || 
                         understanding.contains("ç•Œé¢") || approach.contains("ç•Œé¢")),
                ("å“åº”å¼", understanding.contains("responsive") || approach.contains("responsive") ||
                         understanding.contains("å“åº”å¼") || approach.contains("å“åº”å¼")),
            ]
        },
        "æœºå™¨å­¦ä¹ ä»»åŠ¡" => {
            vec![
                ("PyTorch", understanding.contains("pytorch") || approach.contains("pytorch")),
                ("å›¾åƒåˆ†ç±»", understanding.contains("image") || approach.contains("image") ||
                           understanding.contains("å›¾åƒ") || approach.contains("å›¾åƒ")),
                ("æ¨¡å‹è®­ç»ƒ", understanding.contains("training") || approach.contains("training") ||
                           understanding.contains("è®­ç»ƒ") || approach.contains("è®­ç»ƒ")),
                ("æ•°æ®é¢„å¤„ç†", understanding.contains("preprocessing") || approach.contains("preprocessing") ||
                             understanding.contains("é¢„å¤„ç†") || approach.contains("é¢„å¤„ç†")),
            ]
        },
        "DevOpsä»»åŠ¡" => {
            vec![
                ("CI/CD", understanding.contains("ci/cd") || approach.contains("ci/cd")),
                ("Docker", understanding.contains("docker") || approach.contains("docker")),
                ("Kubernetes", understanding.contains("kubernetes") || approach.contains("kubernetes")),
                ("ç›‘æ§", understanding.contains("monitoring") || approach.contains("monitoring") ||
                       understanding.contains("ç›‘æ§") || approach.contains("ç›‘æ§")),
            ]
        },
        "æ•°æ®åˆ†æä»»åŠ¡" => {
            vec![
                ("Python", understanding.contains("python") || approach.contains("python")),
                ("pandas", understanding.contains("pandas") || approach.contains("pandas")),
                ("æ•°æ®æ¸…æ´—", understanding.contains("cleaning") || approach.contains("cleaning") ||
                           understanding.contains("æ¸…æ´—") || approach.contains("æ¸…æ´—")),
                ("ç»Ÿè®¡åˆ†æ", understanding.contains("statistical") || approach.contains("statistical") ||
                           understanding.contains("ç»Ÿè®¡") || approach.contains("ç»Ÿè®¡")),
            ]
        },
        _ => vec![]
    };
    
    let detected_count = detected_concepts.iter().filter(|(_, detected)| *detected).count();
    let total_concepts = detected_concepts.len();
    
    println!("  æŠ€æœ¯æ¦‚å¿µè¯†åˆ«: {}/{}", detected_count, total_concepts);
    for (concept, detected) in detected_concepts {
        println!("    {}: {}", concept, if detected { "âœ…" } else { "âŒ" });
    }
    
    if detected_count as f32 / total_concepts as f32 >= 0.75 {
        println!("  ğŸ‰ æ³›åŒ–æ€§èƒ½è‰¯å¥½");
    } else if detected_count > 0 {
        println!("  ğŸ”„ æ³›åŒ–æ€§èƒ½ä¸€èˆ¬");
    } else {
        println!("  âš ï¸ æ³›åŒ–æ€§èƒ½ä¸è¶³");
    }
}